{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tystys17/minigpt/blob/main/Use_minigpt4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now you can use MiniGPT-4 13B/7B in Google Colab\n",
        "\n",
        "## <font color=\"#dd0000\">Notice</font>\n",
        "\n",
        "1. You should be a **Google Colab Pro** user.\n",
        "2. You must use **high level GPU**.\n",
        "\n",
        "Otherwise you will not be able to run MiniGPT-4 in colab!!!"
      ],
      "metadata": {
        "id": "wJNQu3Tj9mla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone repo"
      ],
      "metadata": {
        "id": "W87F1-Di8M9R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WFuEa_H_R14",
        "outputId": "75858a17-3d3d-421d-ca70-647cbf382876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MiniGPT-4'...\n",
            "remote: Enumerating objects: 289, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 289 (delta 109), reused 97 (delta 96), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (289/289), 45.35 MiB | 15.07 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Vision-CAIR/MiniGPT-4.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check gpu"
      ],
      "metadata": {
        "id": "QQzLoKL38P0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQiobft0yXpg",
        "outputId": "23eb39c1-a968-40d5-8cea-44d50d442267"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May  5 19:18:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install package"
      ],
      "metadata": {
        "id": "gSy1wyO38TTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "7p3vtgW1_f5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19265da-bd2b-4284-ed31-892bcbe6195c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/         \u001b[01;34mfigs\u001b[0m/             MiniGPT_4.pdf                README.md\n",
            "demo.py          LICENSE_Lavis.md  PrepareVicuna.md             \u001b[01;34mtrain_configs\u001b[0m/\n",
            "environment.yml  LICENSE.md        prerained_minigpt4_7b.pth    train.py\n",
            "\u001b[01;34meval_configs\u001b[0m/    \u001b[01;34mminigpt4\u001b[0m/         prerained_minigpt4_7b.pth.1\n",
            "\u001b[01;34mexamples\u001b[0m/        \u001b[01;34mMiniGPT-4\u001b[0m/        \u001b[01;34mprompts\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MiniGPT-4/"
      ],
      "metadata": {
        "id": "XPWawh6y_jZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc97d5b-e40e-4a17-eac8-483185d9f684"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MiniGPT-4/MiniGPT-4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get requirements.txt in `https://github.com/WangRongsheng/Use-LLMs-in-Colab/blob/main/MiniGPT-4/requirements.txt`"
      ],
      "metadata": {
        "id": "r0sksdnw-jIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "BzZIcNue_pYn",
        "outputId": "a629062e-b8d0-4d9d-a6bc-d0d97d8107f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q salesforce-lavis\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q accelerate\n",
        "!pip install -q gradio==3.27.0"
      ],
      "metadata": {
        "id": "VyRZwh6X1gYt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q h5py\n",
        "!pip install -q typing-extensions\n",
        "!pip install -q wheel\n",
        "# !pip install -q git+https://github.com/huggingface/transformers.git -U\n",
        "!pip install -q transformers==4.26.1"
      ],
      "metadata": {
        "id": "3QaQcHjT2l6z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pretrained_minigpt4"
      ],
      "metadata": {
        "id": "iftS7jdt8XDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you run 13B , Plaease Download Checkpoint Aligned with Vicuna 13B\n",
        "#!wget https://huggingface.co/wangrongsheng/MiniGPT4/blob/main/pretrained_minigpt4.pth\n",
        "\n",
        "# if you run 7B , Plaease Download Checkpoint Aligned with Vicuna 7B\n",
        "!wget https://huggingface.co/wangrongsheng/MiniGPT4-7B/resolve/main/prerained_minigpt4_7b.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69XCMTuCAVfO",
        "outputId": "2feb8f87-9d19-4d5e-bde5-5f2ca89e6b43"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-05 19:18:39--  https://huggingface.co/wangrongsheng/MiniGPT4-7B/resolve/main/prerained_minigpt4_7b.pth\n",
            "Resolving huggingface.co (huggingface.co)... 18.155.68.38, 18.155.68.121, 18.155.68.44, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.155.68.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/25/fa/25fa880e116eda3d82c5c87b32eb0a7fa8f76b139d70ce756851215ce7a76179/017a9ed588a11ed383711003cf50cf675191420a04689f682fb56fa9bbb8dcbb?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27prerained_minigpt4_7b.pth%3B+filename%3D%22prerained_minigpt4_7b.pth%22%3B&Expires=1683570283&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzI1L2ZhLzI1ZmE4ODBlMTE2ZWRhM2Q4MmM1Yzg3YjMyZWIwYTdmYThmNzZiMTM5ZDcwY2U3NTY4NTEyMTVjZTdhNzYxNzkvMDE3YTllZDU4OGExMWVkMzgzNzExMDAzY2Y1MGNmNjc1MTkxNDIwYTA0Njg5ZjY4MmZiNTZmYTliYmI4ZGNiYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODM1NzAyODN9fX1dfQ__&Signature=xqGF7hDTX-Hj19zfp4zFB9W%7E8OJvVRSXozmY5hzjL-cyf9aHXuQEY9R3YaETeeIh6RTCoTLz2RNwmhVjzCUkoxYViDdrrFMNspK0SHMelFnqp5kV4v4BCqOOR9HdRln%7EUwesyiMJ%7EwBzgm786Bkh9ffV8Igtaf7%7EkW5H-j0ghFwW-o4WTZ7SWW%7EsPw-Epb2jE%7EqSgo7mIfFh6bX3DRZ1q5nfHwzzkJkYjOFxPB5ChasJaDUG3tKmzBA08x8YOsRJpLY7SHhdDni4Op-wH88TZVqFbD8AqK2K-iZyw%7E048JYoWarVLBJsJ8Ls2S9n6pNVRX11FKUEAfMFfWOe%7En71oQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-05-05 19:18:40--  https://cdn-lfs.huggingface.co/repos/25/fa/25fa880e116eda3d82c5c87b32eb0a7fa8f76b139d70ce756851215ce7a76179/017a9ed588a11ed383711003cf50cf675191420a04689f682fb56fa9bbb8dcbb?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27prerained_minigpt4_7b.pth%3B+filename%3D%22prerained_minigpt4_7b.pth%22%3B&Expires=1683570283&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzI1L2ZhLzI1ZmE4ODBlMTE2ZWRhM2Q4MmM1Yzg3YjMyZWIwYTdmYThmNzZiMTM5ZDcwY2U3NTY4NTEyMTVjZTdhNzYxNzkvMDE3YTllZDU4OGExMWVkMzgzNzExMDAzY2Y1MGNmNjc1MTkxNDIwYTA0Njg5ZjY4MmZiNTZmYTliYmI4ZGNiYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODM1NzAyODN9fX1dfQ__&Signature=xqGF7hDTX-Hj19zfp4zFB9W%7E8OJvVRSXozmY5hzjL-cyf9aHXuQEY9R3YaETeeIh6RTCoTLz2RNwmhVjzCUkoxYViDdrrFMNspK0SHMelFnqp5kV4v4BCqOOR9HdRln%7EUwesyiMJ%7EwBzgm786Bkh9ffV8Igtaf7%7EkW5H-j0ghFwW-o4WTZ7SWW%7EsPw-Epb2jE%7EqSgo7mIfFh6bX3DRZ1q5nfHwzzkJkYjOFxPB5ChasJaDUG3tKmzBA08x8YOsRJpLY7SHhdDni4Op-wH88TZVqFbD8AqK2K-iZyw%7E048JYoWarVLBJsJ8Ls2S9n6pNVRX11FKUEAfMFfWOe%7En71oQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.98, 18.155.68.73, 18.155.68.128, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37907201 (36M) [binary/octet-stream]\n",
            "Saving to: ‘prerained_minigpt4_7b.pth’\n",
            "\n",
            "prerained_minigpt4_ 100%[===================>]  36.15M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-05 19:18:40 (244 MB/s) - ‘prerained_minigpt4_7b.pth’ saved [37907201/37907201]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#660000\">Notice</font>\n",
        "\n",
        "## IF you run 13B:\n",
        "\n",
        "- Set `llama_model: \"wangrongsheng/MiniGPT-4-LLaMA\"` in `minigpt4/configs/models/minigpt4.yaml`\n",
        "- Set `ckpt: 'pretrained_minigpt4.pth'` in `eval_configs/minigpt4_eval.yaml`\n",
        "\n",
        "> `wangrongsheng/MiniGPT-4-LLaMA` was created from `vicuna-13b-delta-v0` and `llama-13b-hf`\n",
        "\n",
        "## IF you run 7B:\n",
        "\n",
        "- Set `llama_model: \"wangrongsheng/MiniGPT-4-LLaMA-7B\"` in `minigpt4/configs/models/minigpt4.yaml`\n",
        "- Set `ckpt: 'prerained_minigpt4_7b.pth'` in `eval_configs/minigpt4_eval.yaml`\n",
        "\n",
        "> `wangrongsheng/MiniGPT-4-LLaMA-7B` was created from `vicuna-7b-delta-v0` and `llama-7b-hf`"
      ],
      "metadata": {
        "id": "RqLKLejaDEUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls \n",
        "# %load minigpt4/configs/models/minigpt4.yaml\n",
        "%cat minigpt4/configs/models/minigpt4.yaml\n",
        "# %cat eval_configs/minigpt4_eval.yaml\n",
        "# %%writefile code.py"
      ],
      "metadata": {
        "id": "d4YMDjUIUipZ",
        "outputId": "fcce6a6a-0b46-419f-8021-189d5bb0e367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:\n",
            "  arch: mini_gpt4\n",
            "\n",
            "  # vit encoder\n",
            "  image_size: 224\n",
            "  drop_path_rate: 0\n",
            "  use_grad_checkpoint: False\n",
            "  vit_precision: \"fp16\"\n",
            "  freeze_vit: True\n",
            "  freeze_qformer: True\n",
            "\n",
            "  # Q-Former\n",
            "  num_query_token: 32\n",
            "\n",
            "  # Vicuna\n",
            "  llama_model: \"/path/to/vicuna/weights/\"\n",
            "\n",
            "  # generation configs\n",
            "  prompt: \"\"\n",
            "\n",
            "preprocess:\n",
            "    vis_processor:\n",
            "        train:\n",
            "          name: \"blip2_image_train\"\n",
            "          image_size: 224\n",
            "        eval:\n",
            "          name: \"blip2_image_eval\"\n",
            "          image_size: 224\n",
            "    text_processor:\n",
            "        train:\n",
            "          name: \"blip_caption\"\n",
            "        eval:\n",
            "          name: \"blip_caption\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run MiniGPT-4"
      ],
      "metadata": {
        "id": "lndJLTq89crE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo.py --cfg-path eval_configs/minigpt4_eval.yaml --gpu-id 0"
      ],
      "metadata": {
        "id": "IoPqDP4WC_km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YZwzYXFPEmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}